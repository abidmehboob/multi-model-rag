"""
Test script for Custom Ollama Server Connection
Tests your specific Ollama server configuration
"""

import sys
from custom_ollama import CustomOllama

# Your Ollama server configuration
OLLAMA_MODEL = "gemma2"
OLLAMA_API_URL = "http://20.185.83.16:8080/"
OLLAMA_API_KEY = "aie93JaTv1GW1AP4IIUSqeecV22HgpcQ6WlgWNyfx2HflkY5hTw19JDbT90ViKcZaZ6lpjOo3YIGgpkG7Zb8jEKvdM5Ymnq9jPm79osLppCebwJ7WdWTwWq3Rf15NDxm"
DEFAULT_TEMPERATURE = 0.2

def test_custom_ollama():
    """Test the custom Ollama implementation"""
    print("ğŸ§ª Testing Custom Ollama Server Connection")
    print("=" * 50)
    print(f"ğŸ”— Server URL: {OLLAMA_API_URL}")
    print(f"ğŸ¤– Model: {OLLAMA_MODEL}")
    print(f"ğŸŒ¡ï¸  Temperature: {DEFAULT_TEMPERATURE}")
    print()
    
    try:
        # Initialize custom Ollama
        print("ğŸš€ Initializing Custom Ollama...")
        ollama = CustomOllama(
            model=OLLAMA_MODEL,
            base_url=OLLAMA_API_URL,
            api_key=OLLAMA_API_KEY,
            temperature=DEFAULT_TEMPERATURE
        )
        print("âœ… Custom Ollama initialized")
        
        # Test connection
        print("\nğŸ”Œ Testing server connection...")
        if ollama.test_connection():
            print("âœ… Server connection successful")
        else:
            print("âŒ Server connection failed")
            return False
        
        # Test model listing
        print("\nğŸ“‹ Listing available models...")
        try:
            models = ollama.list_models()
            if models:
                print(f"âœ… Found {len(models)} models:")
                for model in models:
                    print(f"   ğŸ“¦ {model}")
            else:
                print("âš ï¸  No models found or unable to list models")
        except Exception as e:
            print(f"âš ï¸  Could not list models: {e}")
        
        # Test simple query
        print(f"\nğŸ§ª Testing model '{OLLAMA_MODEL}' with simple query...")
        test_prompt = "Hello! Please respond with 'Test successful' to confirm you're working."
        
        response = ollama.invoke(test_prompt)
        print(f"ğŸ“ Model response: {response}")
        
        if response.strip():
            print("âœ… Model is responding correctly")
        else:
            print("âŒ Model returned empty response")
            return False
        
        # Test with a more complex query
        print(f"\nğŸ§ª Testing with more complex query...")
        complex_prompt = "Explain what artificial intelligence is in one sentence."
        
        response = ollama.invoke(complex_prompt)
        print(f"ğŸ“ Complex response: {response[:200]}...")
        
        if len(response.strip()) > 10:
            print("âœ… Model handles complex queries well")
        else:
            print("âŒ Model response seems too short")
            return False
        
        # Test temperature variation
        print(f"\nğŸŒ¡ï¸  Testing temperature variation...")
        ollama_high_temp = CustomOllama(
            model=OLLAMA_MODEL,
            base_url=OLLAMA_API_URL,
            api_key=OLLAMA_API_KEY,
            temperature=0.8
        )
        
        creative_prompt = "Write a creative one-line story about a robot."
        
        response1 = ollama.invoke(creative_prompt)  # Low temperature
        response2 = ollama_high_temp.invoke(creative_prompt)  # High temperature
        
        print(f"ğŸ“ Low temp (0.2): {response1[:100]}...")
        print(f"ğŸ“ High temp (0.8): {response2[:100]}...")
        
        print("âœ… Temperature variation test completed")
        
        print("\nğŸ‰ All tests passed! Your Ollama server is working correctly.")
        return True
        
    except Exception as e:
        print(f"âŒ Test failed with error: {e}")
        return False

def main():
    """Main test function"""
    print("ğŸ¦™ Custom Ollama Server Test Suite")
    print("Testing your remote Ollama configuration")
    print()
    
    # Test the custom implementation
    success = test_custom_ollama()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š Test Summary:")
    
    if success:
        print("âœ… All tests passed!")
        print("ğŸš€ Your RAG application should work correctly.")
        print("\nğŸ’¡ Next steps:")
        print("   1. Run: py simple_rag_app.py")
        print("   2. Or run: py run_app.py")
    else:
        print("âŒ Some tests failed.")
        print("\nğŸ”§ Troubleshooting:")
        print("   1. Check if the server URL is accessible")
        print("   2. Verify the API key is correct")
        print("   3. Ensure the model 'gemma2' is available on the server")
        print("   4. Check network connectivity")
    
    return success

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Test cancelled by user")
        sys.exit(1)
